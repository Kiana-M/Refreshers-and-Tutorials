{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOfTNLpUb+D4Ol/ZiH9M9pW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kiana-M/Refreshers-and-Tutorials/blob/main/OOP_Mockinterview_Practice.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let’s dive into a mock interview question that ties in data quality monitoring and OOP fundamentals.\n",
        "\n",
        "---\n",
        "\n",
        "**Interview Question:**\n",
        "\n",
        "\"Let's design a basic **Data Quality Monitoring System** in Python. This system should allow us to track data quality metrics for different data sources, such as completeness and uniqueness. We'll structure it to follow OOP principles, making it modular and extensible for future metrics.\"\n",
        "\n",
        "### Requirements\n",
        "\n",
        "1. **Abstract Base Class**: Create an abstract base class `DataQualityMetric`, which defines the blueprint for all metrics.\n",
        "   - This class should have an `evaluate` method that will be implemented in each concrete metric.\n",
        "\n",
        "2. **Concrete Metrics**: Define at least two concrete classes that inherit from `DataQualityMetric`:\n",
        "   - **CompletenessMetric**: Checks for missing values in a data source.\n",
        "   - **UniquenessMetric**: Checks for duplicate entries in a data source.\n",
        "   \n",
        "3. **DataSource Class**: A `DataSource` class represents the data to be monitored. It has a method to load data and another method to run metrics on it.\n",
        "\n",
        "4. **MetricEvaluator Class**: Finally, a class `MetricEvaluator` that takes in a `DataSource` and a list of `DataQualityMetric` objects, and evaluates each metric on the data source.\n",
        "\n",
        "**Assume we’re working with a pandas DataFrame as the data source.**\n",
        "\n",
        "---\n",
        "\n",
        "### Example Usage\n",
        "\n",
        "Here's a quick example of what this would look like when put together:\n",
        "\n",
        "```python\n",
        "import pandas as pd\n",
        "\n",
        "# Define some data with missing values and duplicates for testing\n",
        "data = pd.DataFrame({\n",
        "    \"id\": [1, 2, 3, 4, None, 5, 2],\n",
        "    \"name\": [\"Alice\", \"Bob\", None, \"David\", \"Eve\", \"Frank\", \"Alice\"]\n",
        "})\n",
        "```\n",
        "\n",
        "Then, the code should work like this:\n",
        "\n",
        "```python\n",
        "source = DataSource(data)\n",
        "evaluator = MetricEvaluator(source, [CompletenessMetric(), UniquenessMetric()])\n",
        "results = evaluator.evaluate()\n",
        "print(results)\n",
        "```\n",
        "\n",
        "### Let’s Begin the Design\n",
        "\n",
        "1. **Step 1**: Start by defining the `DataQualityMetric` base class with the `evaluate` method.\n",
        "  \n",
        "2. **Step 2**: Implement `CompletenessMetric` and `UniquenessMetric` classes that inherit from `DataQualityMetric`.\n",
        "\n",
        "---\n",
        "\n",
        "Let’s start with **Step 1**: Go ahead and define the `DataQualityMetric` class as an abstract class, including the `evaluate` method.\n",
        "\n",
        "Let me know if you'd like me to help clarify any part or proceed to the next steps!"
      ],
      "metadata": {
        "id": "6kBFwIbVP1m_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MPDF785XPyA4"
      },
      "outputs": [],
      "source": [
        "\n",
        "from abc import ABC, abstractmethod\n",
        "\n",
        "class DataQualityMetric(ABC):\n",
        "\n",
        "    @abstractmethod\n",
        "    def evaluate(self):\n",
        "        raise NotImplementedError(\"Subclasses must implement this method.\")\n",
        "\n",
        "\n",
        "class CompletenessMetric(DataQualityMetric):\n",
        "    #Checks for missing values in a data source.\n",
        "\n",
        "    def evaluate(self, df):\n",
        "        if df.isnull().sum().sum() == 0:\n",
        "            return False\n",
        "        else:\n",
        "            return True\n",
        "\n",
        "\n",
        "class UniquenessMetric(DataQualityMetric):\n",
        "    #Checks for duplicate entries in a data source.\n",
        "\n",
        "    def evaluate(self, df):\n",
        "        if len(df) == len(df.drop_duplicates()):\n",
        "            return False\n",
        "        else:\n",
        "            return True\n",
        "\n",
        "class DataSource:\n",
        "    def __init__(self, data):\n",
        "        self.__data = data\n",
        "\n",
        "    @property\n",
        "    def load_data(self):\n",
        "        return self.__data\n",
        "\n",
        "\n",
        "class MetricEvaluator:\n",
        "    def __init__(self, source: DataSource, metric_list: list[DataQualityMetric]):\n",
        "        self.data = source\n",
        "        self.metric_list = metric_list\n",
        "\n",
        "    def run_metrics(self):\n",
        "        results = {}\n",
        "        if self.data.load_data.empty:\n",
        "            raise ValueError('No data')\n",
        "        for metric in self.metric_list:\n",
        "            metric_name = metric.__class__.__name__\n",
        "            results[metric_name] = metric.evaluate(self.data.load_data)\n",
        "        return results\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Define some data with missing values and duplicates for testing\n",
        "data = pd.DataFrame({\n",
        "    \"id\": [1, 2, 3, 4, None, 5, 2],\n",
        "    \"name\": [\"Alice\", \"Bob\", None, \"David\", \"Eve\", \"Frank\", \"Alice\"]\n",
        "})\n"
      ],
      "metadata": {
        "id": "TCaNgDSpBFeN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "source = DataSource(data)\n",
        "evaluator = MetricEvaluator(source, [CompletenessMetric(), UniquenessMetric()])\n",
        "results = evaluator.run_metrics()\n",
        "print(results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2DqoBBttBMqq",
        "outputId": "692a0dc2-ae8b-4cd8-c043-e16daaed6a4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'CompletenessMetric': True, 'UniquenessMetric': False}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Interview Question\n",
        "\n",
        "You’re tasked with designing a simple event monitoring system that can track and report various events within a data pipeline (e.g., data ingestion started, data validation failed, data export completed, etc.). The system needs to support different types of events and allow adding custom event types in the future. Your solution should be modular and flexible, allowing us to easily integrate it into a larger system.\n",
        "\n",
        "Requirements:\n",
        "\n",
        "\t1.\tEvent Base Class: Create an Event base class that will represent a general event. Each event should have a name (str) and a timestamp (use datetime.now()).\n",
        "\t2.\tEvent Types: Define three specific event classes that inherit from Event:\n",
        "\t  •\tDataIngestionEvent - triggered when data ingestion starts. It should include source (str) as an additional attribute.\n",
        "\t  •\tDataValidationEvent - triggered when data validation fails. It should include validation_errors (list of str).\n",
        "\t  •\tDataExportEvent - triggered when data export completes. It should include destination (str).\n",
        "\t3.\tEvent Logger: Create an EventLogger class responsible for tracking and reporting events. It should have:\n",
        "\t  •\tA method log_event that accepts an Event instance and stores it.\n",
        "\t  •\tA method get_report that returns a summary of all logged events in a human-readable format.\n",
        "\t  •\tOptionally, add a way to filter events based on their type (e.g., get all DataValidationEvent logs).\n",
        "\t4.\tFuture Compatibility: Design the code so adding a new event type, like DataTransformationEvent, would require minimal changes to the existing system.\n",
        "\n",
        "Bonus:\n",
        "\n",
        "Make Event a bit more interesting by enforcing that each subclass must implement a get_details method that provides information specific to the event type (e.g., data source or validation errors). This method should be called by EventLogger when generating the report.\n",
        "\n",
        "Take a few minutes to think about the structure and let me know when you’re ready to start. If you get stuck, I’ll give you some pointers.\n"
      ],
      "metadata": {
        "id": "h-anWIvumQaM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from abc import ABC, abstractmethod\n",
        "from datetime import datetime\n",
        "\n",
        "class Event(ABC):\n",
        "    def __init__(self, name: str):\n",
        "        self.name = name\n",
        "        self.time_stamp = datetime.now()\n",
        "\n",
        "    @abstractmethod\n",
        "    def get_report(self):\n",
        "        raise NotImplementedError(\"Defined in concrete classes\")\n",
        "\n",
        "class DataIngestionEvent(Event):\n",
        "    # triggered when data ingestion starts\n",
        "    def __init__(self, name: str, source: str):\n",
        "        super().__init__(name)\n",
        "        self._source = source  # Using single underscore for encapsulation\n",
        "\n",
        "    @property\n",
        "    def source(self):\n",
        "        return self._source\n",
        "\n",
        "    def get_report(self):\n",
        "        return f\"{self.time_stamp} - Data ingestion started for {self.name} from source {self.source}\"\n",
        "\n",
        "class DataValidationEvent(Event):\n",
        "    # triggered when data validation fails\n",
        "    def __init__(self, name: str, validation_errors: list[str]):\n",
        "        super().__init__(name)\n",
        "        self.__validation_errors = validation_errors\n",
        "\n",
        "    @property\n",
        "    def validation_errors(self):\n",
        "        return self.__validation_errors\n",
        "\n",
        "    def get_report(self):\n",
        "        message = f\"{self.time_stamp} - Data validation failed for {self.name}. Error List:\"\n",
        "        for error in self.validation_errors:\n",
        "            message += '\\n' + error\n",
        "        return message\n",
        "\n",
        "class DataExportEvent(Event):\n",
        "    # triggered when data export completes\n",
        "    def __init__(self, name: str, destination: str):\n",
        "        super().__init__(name)\n",
        "        self.__destination = destination\n",
        "\n",
        "    @property\n",
        "    def destination(self):\n",
        "        return self.__destination\n",
        "\n",
        "    def get_report(self):\n",
        "        return f\"{self.time_stamp} - Data export completed for {self.name} to destination {self.destination}\"\n",
        "\n",
        "class EventLogger:\n",
        "    def __init__(self):\n",
        "        self.events = []  # Initialize as an empty list\n",
        "\n",
        "    def log_event(self, event: Event):\n",
        "        self.events.append(event)\n",
        "\n",
        "    def get_reports(self):\n",
        "        for event in self.events:\n",
        "            print(event.get_report())\n",
        ""
      ],
      "metadata": {
        "id": "r0QsbovBoXZR"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "LrYP1b10Fr4X"
      }
    }
  ]
}